# -*- coding: utf-8 -*-
"""lstm_stockprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dxaEYop80BUxugNxaJdPiKShXjSQBnfw
"""

import pandas as pd

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/TSLA.csv')

# Display first few rows
print(df.head())

# Check for missing values in the 'Close' column
missing_values = df['Close'].isnull().sum()
print(f"Missing values in 'Close': {missing_values}")

# Fill missing values (if any) using forward fill or interpolation
if missing_values > 0:
    df['Close'] = df['Close'].fillna(method='ffill')  # Forward fill
    # Alternative: Use interpolation
    # df['Close'] = df['Close'].interpolate(method='linear')
    print("Missing values have been handled.")

# Detect outliers using IQR
Q1 = df['Close'].quantile(0.25)  # First quartile
Q3 = df['Close'].quantile(0.75)  # Third quartile
IQR = Q3 - Q1  # Interquartile range

# Define outlier bounds
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Find outliers
outliers = df[(df['Close'] < lower_bound) | (df['Close'] > upper_bound)]
print(f"Number of outliers: {len(outliers)}")

# Optionally, remove or cap outliers
df['Close'] = df['Close'].clip(lower=lower_bound, upper=upper_bound)
print("Outliers have been handled.")

import matplotlib.pyplot as plt

# Plot the data and outliers
plt.figure(figsize=(12, 6))
plt.plot(df['Close'], label='Close Prices')
plt.scatter(outliers.index, outliers['Close'], color='red', label='Outliers', marker='x')
plt.title('Outliers in Stock Prices')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'df' is your DataFrame with the 'Close' column

# Calculate the 7-day moving average and assign it to a new column 'Close_Smoothed'
df['Close_Smoothed'] = df['Close'].rolling(window=7, center=True).mean()

plt.figure(figsize=(12, 6))
plt.plot(df['Close'], label='Original Close Prices', alpha=0.5)
plt.plot(df['Close_Smoothed'], label='Smoothed Close Prices (7-day MA)', color='red')
plt.title('Original vs Smoothed Close Prices')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

# Remove outliers
df_cleaned = df[(df['Close'] >= lower_bound) & (df['Close'] <= upper_bound)]
print(f"Removed {len(df) - len(df_cleaned)} outliers.")

# Replace outliers with median (or mean) value
median_value = df['Close'].median()
df['Close'] = np.where((df['Close'] < lower_bound) | (df['Close'] > upper_bound), median_value, df['Close'])

# Add a moving average column (e.g., 7-day moving average)
df['Close_Smoothed'] = df['Close'].rolling(window=7).mean()

# Fill NaN values caused by moving average (e.g., at the start)
df['Close_Smoothed'] = df['Close_Smoothed'].fillna(df['Close'])

# Use 'Close_Smoothed' for model training
print("Data has been smoothed using a 7-day moving average.")

# Extract 'Close' column as we aim to predict this value
data = df['Close'].values.reshape(-1, 1)

# Scale data to be between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
data_scaled = scaler.fit_transform(data)

#The MinMaxScaler operation is applied to the data to normalize it,
#which ensures that the values are scaled to a specific range (in this case, between 0 and 1). This step is crucial for optimizing the performance of machine learning models, especially for deep learning models like LSTMs
#Ensures that all values are on the same scale, making them comparable..

# Function to create sequences
def create_sequences(data, seq_length):
    X, y = [], []
    for i in range(seq_length, len(data)):
        X.append(data[i-seq_length:i, 0])  # Past `seq_length` values
        y.append(data[i, 0])  # Target value (next value in sequence)
    return np.array(X), np.array(y)

# Set sequence length
sequence_length = 60
X, y = create_sequences(data_scaled, sequence_length)

# Reshape data for LSTM: (samples, time steps, features)
X = np.reshape(X, (X.shape[0], X.shape[1], 1))
print(X)

#This code segment is essential for preparing the data for use in an LSTM model, which requires sequential data with a specific input structure.

# Split data into 80% training and 20% test
split = int(0.8 * len(X))
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# Define the LSTM model
model = Sequential([
    LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    LSTM(100, return_sequences=False),
    Dense(50),
    Dense(1)
])


# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

from tensorflow.keras.layers import Dropout

model = Sequential([
    LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], 1)),
    Dropout(0.2),
    LSTM(100, return_sequences=False),
    Dropout(0.2),
    Dense(50),
    Dense(1)
])

# Compile the model
# This line was missing after redefining the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Early stopping for better performance
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32, callbacks=[early_stop])

#training and testing accuracy

# Plot training and validation loss
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

# Generate predictions
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Invert predictions and actual values back to original scale
train_predict = scaler.inverse_transform(train_predict)  # Convert back to original scale
y_train_actual = scaler.inverse_transform(y_train.reshape(-1, 1))  # Ensure proper scaling

test_predict = scaler.inverse_transform(test_predict)
y_test_actual = scaler.inverse_transform([y_test])

train_predict = train_predict.flatten()  # Flatten predictions if needed
y_train_actual = y_train_actual.flatten()  # Flatten actual values

# Predict and scale back to original values
predicted = model.predict(X_test)
predicted_prices = scaler.inverse_transform(predicted)

# Reshape y_test for inverse scaling
real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np

# Training Metrics
train_r2 = r2_score(y_train_actual, train_predict)
train_mae = mean_absolute_error(y_train_actual, train_predict)
train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_predict))
train_mape = np.mean(np.abs((y_train_actual - train_predict) / (y_train_actual + 1e-10))) * 100
train_accuracy = 100 - train_mape

# Testing Metrics
test_r2 = r2_score(real_prices.flatten(), predicted_prices.flatten())
test_mae = mean_absolute_error(real_prices.flatten(), predicted_prices.flatten())
test_rmse = np.sqrt(mean_squared_error(real_prices.flatten(), predicted_prices.flatten()))
test_mape = np.mean(np.abs((real_prices.flatten() - predicted_prices.flatten()) / (real_prices.flatten() + 1e-10))) * 100
test_accuracy = 100 - test_mape

# Print Metrics
print("Training Metrics:")
print(f"R-Squared: {train_r2 * 100:.2f}%")
print(f"Mean Absolute Error (MAE): {train_mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {train_rmse:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {train_mape:.2f}%")
print(f"Prediction Accuracy: {train_accuracy:.2f}%\n")

print("Testing Metrics:")
print(f"R-Squared: {test_r2 * 100:.2f}%")
print(f"Mean Absolute Error (MAE): {test_mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {test_rmse:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {test_mape:.2f}%")
print(f"Prediction Accuracy: {test_accuracy:.2f}%")



plt.figure(figsize=(12, 6))
plt.plot(real_prices, color='yellow', label='Actual TSLA Stock Price')
plt.plot(predicted_prices, color='red', label='Predicted TSLA Stock Price')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()